{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109f804c-8d6f-4428-a63c-791b1357272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy\n",
    "\n",
    "#Load the Excel file of Kene's dataset\n",
    "excel_file_path = 'SignPostageData/signage_data.xlsx'\n",
    "\n",
    "#Read it using pandas\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "#Split the data into the main dataset and metadata\n",
    "sign_location_data = df.iloc[:42]  # Data rows (1 to 42 inclusive)\n",
    "metadata_df = df.iloc[45:48]  # Metadata rows (46 to 48)\n",
    "\n",
    "\n",
    "#--------------------------------------TO FIX MANY FORMAT ISSUES I ENCOUNTERED---------------------------------\n",
    "\n",
    "#Clean the data by removing non-breaking spaces and unwanted smart quotes\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.replace(u'\\xa0', ' ') # Replace non-breaking spaces with normal spaces\n",
    "        text = text.replace(u'\\u2019', \"'\") # Replace smart single quote ’ with straight '\n",
    "        text = text.replace(u'\\u201d', '\"') # Replace smart double quote ” with straight \"\n",
    "        text = text.replace(u'\\u2018', \"'\") # Replace left single quote with straight '\n",
    "        text = text.replace(u'\\u201c', '\"') # Replace left double quote with straight \"\n",
    "        text = text.replace(u'\\xc2\\xb0', '°') # Properly encode the degree symbol\n",
    "        text = text.replace(u'\\xc2\\xb4', \"'\")  # Replace byte-encoded acute accent with plain apostrophe\n",
    "    return text\n",
    "    \n",
    "#Apply cleaning to the whole dataframe\n",
    "sign_location_data = sign_location_data.map(clean_text)\n",
    "\n",
    "#Check for missing or incompatible data types and handle them-NaN -> empty strings or 0 for numeric values\n",
    "sign_location_data = sign_location_data.fillna('')  \n",
    "metadata_df = metadata_df.fillna('')  \n",
    "\n",
    "# Convert all columns to string type to ensure they are stored as readable text\n",
    "sign_location_data = sign_location_data.astype(str)\n",
    "\n",
    "for column in sign_location_data.columns:\n",
    "    if sign_location_data[column].dtype == 'O':  #'O' stands for object\n",
    "        sign_location_data[column] = sign_location_data[column].astype(str)  #Convert object types to strings\n",
    "\n",
    "#Convert the DataFrame to a list of lists\n",
    "sign_location_data_list = sign_location_data.values.tolist()\n",
    "\n",
    "\n",
    "#-------------------------------------------------EXTRACT_METADATA----------------------------------------------\n",
    "\n",
    "#print(metadata_df)\n",
    "metadata_row_1 = df.loc[44, 'Location'] #about the dataset\n",
    "metadata_row_2 = df.loc[45, 'Location'] #about the collection tool\n",
    "metadata_row_3 = df.loc[46, 'Location'] #about the latitude/longitude formaT\n",
    "\n",
    "# Convert metadata to a dictionary\n",
    "metadata_dict = {\n",
    "    \"Dataset_Description\": metadata_row_1,\n",
    "    \"Collection_Tool\": metadata_row_2,\n",
    "    \"Latitude_Longitude_Format\": metadata_row_3\n",
    "}\n",
    "\n",
    "#---------------------------------------------CREATE_HDF5_FILE--------------------------------------------------\n",
    "\n",
    "#Create the HDF5 file\n",
    "hdf5_file_name = 'SignLocations.h5'\n",
    "with h5py.File(hdf5_file_name, 'w') as h5_file:\n",
    "    \n",
    "    #Create a group for the sign location data\n",
    "    sign_group = h5_file.create_group('SignLocationData')\n",
    "    \n",
    "    #Store the sign location data as a single dataset- keep row-based relationships intact\n",
    "    # Store the sign location data as variable-length UTF-8 strings\n",
    "    dt = h5py.string_dtype(encoding='utf-8') \n",
    "    sign_location_dataset = sign_group.create_dataset('SignLocations', (len(sign_location_data_list), len(sign_location_data_list[0])), dtype=dt)\n",
    "\n",
    "    #Populate the dataset row-by-row (to avoid storing as byte strings)\n",
    "    for i, row in enumerate(sign_location_data_list):\n",
    "        sign_location_dataset[i] = row  #Assign each row to the dataset\n",
    "    \n",
    "    #-----------------------------------METADATA INFORMATION-------------------------------------------------------\n",
    "    \n",
    "    #Add metadata to the group\n",
    "    sign_group.attrs['source'] = 'Sign Location Data Collection by Kene Nwachukwu'\n",
    "    sign_group.attrs['extraction_method'] = 'Measurement Data Collection'\n",
    "    sign_group.attrs['latitude_longitude_format'] = metadata_dict['Latitude_Longitude_Format']\n",
    "    sign_group.attrs['collection_tool'] = metadata_dict['Collection_Tool']\n",
    "    sign_group.attrs['dataset_description'] = metadata_dict['Dataset_Description']\n",
    "\n",
    "    #Additional metadata about the origin, conversion process, and overall data/file\n",
    "    h5_file.attrs['origin'] = \"Collected and Provided by Kene Nwachukwu\"\n",
    "    h5_file.attrs['conversion_process'] = \"Converted from Excel to HDF5 with metadata extraction\"\n",
    "    h5_file.attrs['file_creation_date'] = '2024-10-18'\n",
    "    h5_file.attrs['description'] = 'Sign location data around RPI campus collected by Kene Nwachukwu for 2023-2024'\n",
    "\n",
    "    \n",
    "    #Store the original metadata lines that Kene provided at the bottom of the Excel-\n",
    "    #Create a README.md file with the metadata content\n",
    "    readme_file_path = 'README.md'\n",
    "    with open(readme_file_path, 'w') as f:\n",
    "        f.write(f\"# Sign Location Data Collection Metadata\\n\\n\")\n",
    "        f.write(f\"**Dataset Description**: {metadata_dict['Dataset_Description']}\\n\")\n",
    "        f.write(f\"**Data Collection Tool**: {metadata_dict['Collection_Tool']}\\n\")\n",
    "        f.write(f\"**Latitude/Longitude Format**: {metadata_dict['Latitude_Longitude_Format']}\\n\")\n",
    "\n",
    "    \n",
    "    if os.path.exists(readme_file_path):\n",
    "            with open(readme_file_path, 'r') as f:\n",
    "                readme_content = f.read()\n",
    "            h5_file.attrs['readme_markdown'] = readme_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074d2094-fff3-43a4-9f87-d6f1398384a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups in the HDF5 file:\n",
      "SignLocationData\n",
      "\n",
      "Datasets in 'SignLocationData':\n",
      "SignLocations\n",
      "\n",
      "Decoded Sign Locations Data (First 5 rows):\n",
      "['1.      ', 'Alan Computing signage', '42°  43\\' 45\" N', '73° 40\\' 56\" W', '72.58', '2024-09-13-13-30']\n",
      "['2.      ', 'Map 1 ', '42° 43´ 47\" N', '73° 40´ 56\"W', '70.37', '2024-09-13-13-29']\n",
      "['3.      ', 'Amos Eaton signpost', '42° 43´ 48\" N', '73° 40´56 \" W', '70.22', '2024-09-13-13-28']\n",
      "['4.      ', 'Lally signpost', '42° 43´ 48\" N', '73° 40´ 55\" W', '71.47', '2024-09-13-13-27']\n",
      "['5.      ', 'Map2 ', '42° 43´ 49\" N', '73° 40´ 54\" W', '70.67', '2024-09-13-13-26']\n",
      "\n",
      "File-level metadata:\n",
      "conversion_process: Converted from Excel to HDF5 with metadata extraction\n",
      "description: Sign location data around RPI campus collected by Kene Nwachukwu for 2023-2024\n",
      "file_creation_date: 2024-10-18\n",
      "origin: Collected and Provided by Kene Nwachukwu\n",
      "readme_markdown: # Sign Location Data Collection Metadata\n",
      "\n",
      "**Dataset Description**: Dataset consists locations of maps around campus and locations of signposts naming buildings\n",
      "**Data Collection Tool**: *Data was collected using Google Maps on a smart phone\n",
      "**Latitude/Longitude Format**: ** Latitude and Longitude are in degrees , minutes and seconds\n",
      "\n",
      "\n",
      "Group-level metadata (SignLocationData):\n",
      "collection_tool: *Data was collected using Google Maps on a smart phone\n",
      "dataset_description: Dataset consists locations of maps around campus and locations of signposts naming buildings\n",
      "extraction_method: Measurement Data Collection\n",
      "latitude_longitude_format: ** Latitude and Longitude are in degrees , minutes and seconds\n",
      "source: Sign Location Data Collection by Kene Nwachukwu\n"
     ]
    }
   ],
   "source": [
    "#Read the file and metadata to ensure the conversion worked properly\n",
    "\n",
    "hdf5_file_name = 'SignLocations.h5'\n",
    "\n",
    "#Open the HDF5 file\n",
    "with h5py.File(hdf5_file_name, 'r') as h5_file:\n",
    "    \n",
    "    #List all groups in the file\n",
    "    print(\"Groups in the HDF5 file:\")\n",
    "    for group_name in h5_file:\n",
    "        print(group_name)\n",
    "    \n",
    "    #Access the group\n",
    "    sign_group = h5_file['SignLocationData']\n",
    "\n",
    "    #List datasets in the group\n",
    "    print(\"\\nDatasets in 'SignLocationData':\")\n",
    "    for dataset_name in sign_group:\n",
    "        print(dataset_name)\n",
    "    \n",
    "    #Read the dataset \n",
    "    sign_locations_data = sign_group['SignLocations'][:]\n",
    "    \n",
    "    #Convert byte strings to regular strings\n",
    "    decoded_data = []\n",
    "    for row in sign_locations_data:\n",
    "        decoded_row = [cell.decode('utf-8') if isinstance(cell, bytes) else cell for cell in row]\n",
    "        decoded_data.append(decoded_row)\n",
    "\n",
    "    print(\"\\nDecoded Sign Locations Data (First 5 rows):\")\n",
    "    for row in decoded_data[:5]:\n",
    "        print(row)   \n",
    "\n",
    "\n",
    "   #Reading file-level metadata\n",
    "    print(\"\\nFile-level metadata:\")\n",
    "    for key, value in h5_file.attrs.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    #Reading group-level metadata\n",
    "    print(\"\\nGroup-level metadata (SignLocationData):\")\n",
    "    for key, value in sign_group.attrs.items():\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0acb80a-e4cc-48f0-afd9-e42a6f7a74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'master' set up to track 'origin/master'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:thernandez7/Sign_Location_data_conversion_HDF5.git\n",
      "   05c4ed6..21ce1d5  master -> master\n"
     ]
    }
   ],
   "source": [
    "#!pwd\n",
    "#!git init\n",
    "#!git add .\n",
    "#!git commit -m \"Added AIP files\"\n",
    "#!git remote add origin git@github.com:thernandez7/Sign_Location_data_conversion_HDF5.git\n",
    "!git push -u origin master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
